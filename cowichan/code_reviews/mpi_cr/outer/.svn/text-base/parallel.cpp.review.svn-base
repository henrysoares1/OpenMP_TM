     1	/**
     2	 * Parallel implementation of outer product matrix
     3	 *
     4	 * \file parallel.cpp
     5	 * \author Andrew Borzenko
     6	 * \date 02-27-09
     7	 */
     8	
     9	#include "../include/main.h"
    10	#include "parallel.h"
    11	
    12	/*
    13	 * @ outer : body of outer product matrix calculation
    14	 * > none
    15	 * + fill matrix
    16	 */
    17	
    18	void
    19	outer_mpi(mpi::communicator world,
    20	  pt1D*		ptVec,			/* vector of points */
    21	  real2D*	matrix,			/* matrix to fill */
    22	  real1D*	realVec,		/* vector to fill */
    23	  int		n			/* size */
    24	){
    25	  int		lo, hi;		/* work controls */
    26	  int		r, c;			/* loop indices */
    27	  real		d;			/* distance */
    28	  real d_max_local = -1.0; // maximum distance
    29	  real d_max; // maximum distance
    30	  bool		work;			/* do useful work? */
    31	  int i, j;
    32	
    33	  /* all elements except matrix diagonal */
    34	  work = get_block_rows_mpi (world, 0, n, &lo, &hi);
    35	  if (work) {
    36	    for (r = lo; r < hi; r++) {
    
In keeping with C++ I suggest this be made into a class method.
    
    37	      realVec[r] = ptMag(&(ptVec[r]));
    38	      for (c = 0; c < r; c++) {

The same for ptDist(p1, p2).

    39	        d = ptDist (&(ptVec[r]), &(ptVec[c]));
    40	        if (d > d_max_local) {
    41	          d_max_local = d;
    42	        }
    43	        // fill columns 0 to r only
    44	        matrix[r][c] = d;
    45	      }
    46	    }
    47	  }
    48	
    
Is it possible that at this point the diagonal and other untouched values
have large values in them that could influence d_max?
    
    49	  // reduce to maximum d's
    50	  all_reduce (world, d_max_local, d_max, mpi::maximum<real>());
    51	  
    52	  /* matrix diagonal */
    53	  d = d_max * n;
    54	  if (work) {
    55	    for (r = lo; r < hi; r++) {
    56	      matrix[r][r] = d;
    57	    }
    58	  }
    59	
    60	  // broadcast matrix, realVec
    61	  for (i = 0; i < world.size (); i++) {
    62	    if (get_block_rows_mpi (world, 0, n, &lo, &hi, i)) {
    63	      broadcast (world, &realVec[lo], hi - lo, i);
    64	      // broadcast row by row since n may be smaller than MAXEXT

I don't understand this comment, fully. Wouldn't you have to broadcast row-by-
row anyhow?

    65	      for (j = lo; j < hi; j++) {
    66	        broadcast (world, matrix[j], n, i);
    67	      }
    68	    }
    69	  }
    70	
    71	  // fill in the rest to make symmetric matrix

This could definitely be parallelized!

    72	  for (r = 0; r < n; r++) {
    73	    for (c = 0; c < r; c++) {
    74	      matrix[c][r] = matrix[r][c];
    75	    }
    76	  }
    77	
    78	  /* return */
    79	}
